{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!pip install scikit-image\n",
    "### Need to complete this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_validate_lengths' from 'numpy.lib.arraypad' (C:\\Users\\admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\lib\\arraypad.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2aa927db6931>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# for reading and displaying images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\admin\\Anaconda3\\lib\\site-packages\\skimage\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    174\u001b[0m                              dtype_limits)\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookfor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlookfor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\admin\\Anaconda3\\lib\\site-packages\\skimage\\util\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mapply_parallel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapply_parallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0marraycrop\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcrop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_regular_grid\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregular_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregular_seeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0munique_rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\admin\\Anaconda3\\lib\\site-packages\\skimage\\util\\arraycrop.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marraypad\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_validate_lengths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_validate_lengths' from 'numpy.lib.arraypad' (C:\\Users\\admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\lib\\arraypad.py)"
     ]
    }
   ],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "# torchvision for pre-trained models\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading training images\n",
    "train_img = []\n",
    "for img_name in tqdm(train['image_names']):\n",
    "    # defining the image path\n",
    "    image_path = 'Emergency_vs_non-emergency_dataset/images/' + img_name\n",
    "    # reading the image\n",
    "    img = imread(image_path)\n",
    "    # normalizing the pixel values\n",
    "    img = img/255\n",
    "    # resizing the image to (224,224,3)\n",
    "    img = resize(img, output_shape=(224,224,3), mode='constant', anti_aliasing=True)\n",
    "    # converting the type of pixel to float 32\n",
    "    img = img.astype('float32')\n",
    "    # appending the image into the list\n",
    "    train_img.append(img)\n",
    "\n",
    "# converting the list to numpy array\n",
    "train_x = np.array(train_img)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the data\n",
    "index = 10\n",
    "plt.imshow(train_x[index])\n",
    "if (train['emergency_or_not'][index] == 1):\n",
    "    print('It is an Emergency vehicle')\n",
    "else:\n",
    "    print('It is a Non-Emergency vehicle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the target\n",
    "train_y = train['emergency_or_not'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create validation set\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.1, random_state = 13, stratify=train_y)\n",
    "(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training images into torch format\n",
    "train_x = train_x.reshape(1481, 3, 224, 224)\n",
    "train_x  = torch.from_numpy(train_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "train_y = train_y.astype(int)\n",
    "train_y = torch.from_numpy(train_y)\n",
    "\n",
    "# shape of training data\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting validation images into torch format\n",
    "val_x = val_x.reshape(165, 3, 224, 224)\n",
    "val_x  = torch.from_numpy(val_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = val_y.astype(int)\n",
    "val_y = torch.from_numpy(val_y)\n",
    "\n",
    "# shape of validation data\n",
    "val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(3, 4, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(4),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(4, 8, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(8),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(8 * 56 * 56, 2)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model\n",
    "model = Net()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size of the model\n",
    "batch_size = 128\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 15\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "        \n",
    "    permutation = torch.randperm(train_x.size()[0])\n",
    "\n",
    "    training_loss = []\n",
    "    for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = train_x[indices], train_y[indices]\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # in case you wanted a semi-full example\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs,batch_y)\n",
    "\n",
    "        training_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    training_loss = np.average(training_loss)\n",
    "    print('epoch: \\t', epoch, '\\t training loss: \\t', training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for training set\n",
    "prediction = []\n",
    "target = []\n",
    "permutation = torch.randperm(train_x.size()[0])\n",
    "for i in tqdm(range(0,train_x.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = train_x[indices], train_y[indices]\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_x.cuda())\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction.append(predictions)\n",
    "    target.append(batch_y)\n",
    "    \n",
    "# training accuracy\n",
    "accuracy = []\n",
    "for i in range(len(prediction)):\n",
    "    accuracy.append(accuracy_score(target[i],prediction[i]))\n",
    "    \n",
    "print('training accuracy: \\t', np.average(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for validation set\n",
    "prediction_val = []\n",
    "target_val = []\n",
    "permutation = torch.randperm(val_x.size()[0])\n",
    "for i in tqdm(range(0,val_x.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = val_x[indices], val_y[indices]\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_x.cuda())\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction_val.append(predictions)\n",
    "    target_val.append(batch_y)\n",
    "    \n",
    "# validation accuracy\n",
    "accuracy_val = []\n",
    "for i in range(len(prediction_val)):\n",
    "    accuracy_val.append(accuracy_score(target_val[i],prediction_val[i]))\n",
    "    \n",
    "print('validation accuracy: \\t', np.average(accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the pretrained model\n",
    "model = models.vgg16_bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze model weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add on classifier\n",
    "model.classifier[6] = Sequential(\n",
    "                      Linear(4096, 2))\n",
    "for param in model.classifier[6].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size\n",
    "batch_size = 128\n",
    "\n",
    "# extracting features for train data\n",
    "data_x = []\n",
    "label_x = []\n",
    "\n",
    "inputs,labels = train_x, train_y\n",
    "\n",
    "for i in tqdm(range(int(train_x.shape[0]/batch_size)+1)):\n",
    "    input_data = inputs[i*batch_size:(i+1)*batch_size]\n",
    "    label_data = labels[i*batch_size:(i+1)*batch_size]\n",
    "    input_data , label_data = Variable(input_data.cuda()),Variable(label_data.cuda())\n",
    "    x = model.features(input_data)\n",
    "    data_x.extend(x.data.cpu().numpy())\n",
    "    label_x.extend(label_data.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting features for validation data\n",
    "data_y = []\n",
    "label_y = []\n",
    "\n",
    "inputs,labels = val_x, val_y\n",
    "\n",
    "for i in tqdm(range(int(val_x.shape[0]/batch_size)+1)):\n",
    "    input_data = inputs[i*batch_size:(i+1)*batch_size]\n",
    "    label_data = labels[i*batch_size:(i+1)*batch_size]\n",
    "    input_data , label_data = Variable(input_data.cuda()),Variable(label_data.cuda())\n",
    "    x = model.features(input_data)\n",
    "    data_y.extend(x.data.cpu().numpy())\n",
    "    label_y.extend(label_data.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the features into torch format\n",
    "x_train  = torch.from_numpy(np.array(data_x))\n",
    "x_train = x_train.view(x_train.size(0), -1)\n",
    "y_train  = torch.from_numpy(np.array(label_x))\n",
    "x_val  = torch.from_numpy(np.array(data_y))\n",
    "x_val = x_val.view(x_val.size(0), -1)\n",
    "y_val  = torch.from_numpy(np.array(label_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer (stochastic gradient descent) and learning rate\n",
    "optimizer = optim.Adam(model.classifier[6].parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "batch_size = 128\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 30\n",
    "\n",
    "for epoch in tqdm(range(1, n_epochs+1)):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "        \n",
    "    permutation = torch.randperm(x_train.size()[0])\n",
    "\n",
    "    training_loss = []\n",
    "    for i in range(0,x_train.size()[0], batch_size):\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = x_train[indices], y_train[indices]\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # in case you wanted a semi-full example\n",
    "        outputs = model.classifier(batch_x)\n",
    "        loss = criterion(outputs,batch_y)\n",
    "\n",
    "        training_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    training_loss = np.average(training_loss)\n",
    "    print('epoch: \\t', epoch, '\\t training loss: \\t', training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for training set\n",
    "prediction = []\n",
    "target = []\n",
    "permutation = torch.randperm(x_train.size()[0])\n",
    "for i in tqdm(range(0,x_train.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = x_train[indices], y_train[indices]\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.classifier(batch_x.cuda())\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction.append(predictions)\n",
    "    target.append(batch_y)\n",
    "    \n",
    "# training accuracy\n",
    "accuracy = []\n",
    "for i in range(len(prediction)):\n",
    "    accuracy.append(accuracy_score(target[i],prediction[i]))\n",
    "    \n",
    "print('training accuracy: \\t', np.average(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for validation set\n",
    "prediction_val = []\n",
    "target_val = []\n",
    "permutation = torch.randperm(x_val.size()[0])\n",
    "for i in tqdm(range(0,x_val.size()[0], batch_size)):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    batch_x, batch_y = x_val[indices], y_val[indices]\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.classifier(batch_x.cuda())\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    prediction_val.append(predictions)\n",
    "    target_val.append(batch_y)\n",
    "    \n",
    "# validation accuracy\n",
    "accuracy_val = []\n",
    "for i in range(len(prediction_val)):\n",
    "    accuracy_val.append(accuracy_score(target_val[i],prediction_val[i]))\n",
    "    \n",
    "print('validation accuracy: \\t', np.average(accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
